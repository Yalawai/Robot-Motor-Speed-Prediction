{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpONTlAYq9MN"
      },
      "source": [
        "# 1.Loading Data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V2EVr8RUr1SP",
        "outputId": "82db2ff3-c23e-425e-e9a9-8fe6b4ea4fba"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          0          1         2   3         4          5        6         7   \\\n",
            "0   3.955138  11.870423 -2.708559   0  1.566351  10.681844  2.69308  6.687333   \n",
            "1   4.000958   4.238834  1.812858   0  1.566351  10.681844  2.69308  6.687333   \n",
            "2   8.755436   2.019115 -1.135413   0  1.566351  10.681844  2.69308  6.687333   \n",
            "3  11.098697   0.086990  0.044513   0  1.566351  10.681844  2.69308  6.687333   \n",
            "4  10.049046   5.131111 -1.354733   0  1.566351  10.681844  2.69308  6.687333   \n",
            "\n",
            "         8         9       10        11        12        13  \n",
            "0  0.187108  1.678316  8.4906  9.150135 -0.118001 -0.054551  \n",
            "1  0.187108  1.678316  8.4906  9.150135 -0.031162  0.126210  \n",
            "2  0.187108  1.678316  8.4906  9.150135  0.054829 -0.117872  \n",
            "3  0.187108  1.678316  8.4906  9.150135  0.129871  0.005785  \n",
            "4  0.187108  1.678316  8.4906  9.150135  0.027870 -0.126977  \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 19998 entries, 0 to 19997\n",
            "Data columns (total 14 columns):\n",
            " #   Column  Non-Null Count  Dtype  \n",
            "---  ------  --------------  -----  \n",
            " 0   0       19998 non-null  float64\n",
            " 1   1       19998 non-null  float64\n",
            " 2   2       19998 non-null  float64\n",
            " 3   3       19998 non-null  int64  \n",
            " 4   4       19998 non-null  float64\n",
            " 5   5       19998 non-null  float64\n",
            " 6   6       19998 non-null  float64\n",
            " 7   7       19998 non-null  float64\n",
            " 8   8       19998 non-null  float64\n",
            " 9   9       19998 non-null  float64\n",
            " 10  10      19998 non-null  float64\n",
            " 11  11      19998 non-null  float64\n",
            " 12  12      19998 non-null  float64\n",
            " 13  13      19998 non-null  float64\n",
            "dtypes: float64(13), int64(1)\n",
            "memory usage: 2.1 MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load CSV file\n",
        "robo = pd.read_csv('/content/sample_data/RobotData.csv', header=None)\n",
        "\n",
        "print(robo.head())\n",
        "print(robo.info())\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **The data does not contain any null value**\n",
        "## **The data contains only continous data, hence no onehot-encoder**"
      ],
      "metadata": {
        "id": "lGASRSPhni0_"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XvF-lyHjn4te"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "Reference: Chat GPT was used for assistance in development of angle_from_robot_to_candle feature during feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nMqnvUVdmnHc"
      },
      "outputs": [],
      "source": [
        "# Preprocessing\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.impute import KNNImputer\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "def labeling_data(data):\n",
        "\n",
        "  #assigning column name to the data\n",
        "  data.columns = ['X_robot', 'Y_robot', 'Orientation_robot', 'Collision','X_candle1', 'Y_candle1', 'X_candle2', 'Y_candle2','X_candle3', 'Y_candle3',\n",
        "                'X_candle4', 'Y_candle4','X_speed', 'Y_speed']\n",
        "\n",
        "def feature_engineering(x):\n",
        "    x_copy = x.copy()\n",
        "\n",
        "    # Calculate distance to each candle\n",
        "    x_copy['distance_from_robot_to_candle1'] = np.sqrt((x_copy['X_robot'] - x_copy['X_candle1'])**2 + (x_copy['Y_robot'] - x_copy['Y_candle1'])**2)\n",
        "    x_copy['distance_from_robot_to_candle2'] = np.sqrt((x_copy['X_robot'] - x_copy['X_candle2'])**2 + (x_copy['Y_robot'] - x_copy['Y_candle2'])**2)\n",
        "    x_copy['distance_from_robot_to_candle3'] = np.sqrt((x_copy['X_robot'] - x_copy['X_candle3'])**2 + (x_copy['Y_robot'] - x_copy['Y_candle3'])**2)\n",
        "    x_copy['distance_from_robot_to_candle4'] = np.sqrt((x_copy['X_robot'] - x_copy['X_candle4'])**2 + (x_copy['Y_robot'] - x_copy['Y_candle4'])**2)\n",
        "\n",
        "    # Calculate angles to each candle\n",
        "    x_copy['angle_from_robot_to_candle1'] = np.arctan2(x_copy['Y_candle1'] - x_copy['Y_robot'], x_copy['X_candle1'] - x_copy['X_robot'])\n",
        "    x_copy['angle_from_robot_to_candle2'] = np.arctan2(x_copy['Y_candle2'] - x_copy['Y_robot'], x_copy['X_candle2'] - x_copy['X_robot'])\n",
        "    x_copy['angle_from_robot_to_candle3'] = np.arctan2(x_copy['Y_candle3'] - x_copy['Y_robot'], x_copy['X_candle3'] - x_copy['X_robot'])\n",
        "    x_copy['angle_from_robot_to_candle4'] = np.arctan2(x_copy['Y_candle4'] - x_copy['Y_robot'], x_copy['X_candle4'] - x_copy['X_robot'])\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return x_copy\n",
        "\n",
        "\n",
        "def augment_data(X, y, noise_factor=0.05):\n",
        "\n",
        "    # Make a copy of the data to avoid modifying the original\n",
        "    X_noisy = X.copy()\n",
        "\n",
        "    # Add noise to X_robot column\n",
        "    noise_x = np.random.normal(0, noise_factor * X[:, 0].std(), size=len(X[:, 0]))\n",
        "    X_noisy[:, 0] += noise_x\n",
        "\n",
        "    # Add noise to Y_Robot column\n",
        "    noise_y = np.random.normal(0, noise_factor * X[:, 1].std(), size=len(X[:, 1]))\n",
        "    X_noisy[:, 1] += noise_y\n",
        "\n",
        "    # Use both original and augmented data points for training\n",
        "    X_augmented = np.vstack([X_noisy, X])\n",
        "    y_augmented = np.concatenate([y, y])\n",
        "\n",
        "    return X_augmented, y_augmented\n",
        "\n",
        "\n",
        "def replace_missing_values_with_neighbors_data(data, n_neighbors=1):\n",
        "    df_replaced = data.replace('?', np.nan)\n",
        "    imputer = KNNImputer(n_neighbors=n_neighbors)\n",
        "    df_numeric = df_replaced.apply(pd.to_numeric, errors='coerce')\n",
        "    df_imputed = pd.DataFrame(imputer.fit_transform(df_numeric), columns=df_numeric.columns)\n",
        "    return df_imputed\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2adjB2Jpp23D"
      },
      "source": [
        "# DevelopAndEvaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WYlBbV1p3Hc",
        "outputId": "3ebaf3bc-a2b9-4fa1-d212-f46648132258"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1, loss = 0.03968854\n",
            "Validation score: -0.186676\n",
            "Iteration 2, loss = 0.03418977\n",
            "Validation score: 0.072560\n",
            "Iteration 3, loss = 0.03194501\n",
            "Validation score: 0.130583\n",
            "Iteration 4, loss = 0.03001360\n",
            "Validation score: 0.186572\n",
            "Iteration 5, loss = 0.02831074\n",
            "Validation score: 0.236676\n",
            "Iteration 6, loss = 0.02677198\n",
            "Validation score: 0.284129\n",
            "Iteration 7, loss = 0.02539884\n",
            "Validation score: 0.328768\n",
            "Iteration 8, loss = 0.02414074\n",
            "Validation score: 0.369068\n",
            "Iteration 9, loss = 0.02300856\n",
            "Validation score: 0.419377\n",
            "Iteration 10, loss = 0.02197643\n",
            "Validation score: 0.459296\n",
            "Iteration 11, loss = 0.02102685\n",
            "Validation score: 0.503378\n",
            "Iteration 12, loss = 0.02017943\n",
            "Validation score: 0.540521\n",
            "Iteration 13, loss = 0.01938068\n",
            "Validation score: 0.572976\n",
            "Iteration 14, loss = 0.01865062\n",
            "Validation score: 0.597867\n",
            "Iteration 15, loss = 0.01799245\n",
            "Validation score: 0.629625\n",
            "Iteration 16, loss = 0.01735885\n",
            "Validation score: 0.649165\n",
            "Iteration 17, loss = 0.01679091\n",
            "Validation score: 0.658691\n",
            "Iteration 18, loss = 0.01624017\n",
            "Validation score: 0.682458\n",
            "Iteration 19, loss = 0.01573020\n",
            "Validation score: 0.696820\n",
            "Iteration 20, loss = 0.01525423\n",
            "Validation score: 0.708101\n",
            "Iteration 21, loss = 0.01480431\n",
            "Validation score: 0.716169\n",
            "Iteration 22, loss = 0.01435554\n",
            "Validation score: 0.739815\n",
            "Iteration 23, loss = 0.01393887\n",
            "Validation score: 0.741684\n",
            "Iteration 24, loss = 0.01354996\n",
            "Validation score: 0.756825\n",
            "Iteration 25, loss = 0.01317139\n",
            "Validation score: 0.763843\n",
            "Iteration 26, loss = 0.01281701\n",
            "Validation score: 0.764495\n",
            "Iteration 27, loss = 0.01251037\n",
            "Validation score: 0.774735\n",
            "Iteration 28, loss = 0.01218790\n",
            "Validation score: 0.779673\n",
            "Iteration 29, loss = 0.01188908\n",
            "Validation score: 0.778340\n",
            "Iteration 30, loss = 0.01158283\n",
            "Validation score: 0.787666\n",
            "Iteration 31, loss = 0.01127131\n",
            "Validation score: 0.800835\n",
            "Iteration 32, loss = 0.01098772\n",
            "Validation score: 0.795425\n",
            "Iteration 33, loss = 0.01074223\n",
            "Validation score: 0.811618\n",
            "Iteration 34, loss = 0.01049233\n",
            "Validation score: 0.791935\n",
            "Iteration 35, loss = 0.01026598\n",
            "Validation score: 0.816227\n",
            "Iteration 36, loss = 0.01002365\n",
            "Validation score: 0.818119\n",
            "Iteration 37, loss = 0.00978309\n",
            "Validation score: 0.826617\n",
            "Iteration 38, loss = 0.00956975\n",
            "Validation score: 0.824436\n",
            "Iteration 39, loss = 0.00935712\n",
            "Validation score: 0.833487\n",
            "Iteration 40, loss = 0.00917106\n",
            "Validation score: 0.800931\n",
            "Iteration 41, loss = 0.00899444\n",
            "Validation score: 0.831581\n",
            "Iteration 42, loss = 0.00878560\n",
            "Validation score: 0.825138\n",
            "Iteration 43, loss = 0.00863887\n",
            "Validation score: 0.842399\n",
            "Iteration 44, loss = 0.00841731\n",
            "Validation score: 0.844201\n",
            "Iteration 45, loss = 0.00824533\n",
            "Validation score: 0.839275\n",
            "Iteration 46, loss = 0.00807685\n",
            "Validation score: 0.850203\n",
            "Iteration 47, loss = 0.00790336\n",
            "Validation score: 0.845695\n",
            "Iteration 48, loss = 0.00774878\n",
            "Validation score: 0.856804\n",
            "Iteration 49, loss = 0.00763466\n",
            "Validation score: 0.844535\n",
            "Iteration 50, loss = 0.00748539\n",
            "Validation score: 0.857301\n",
            "Iteration 51, loss = 0.00732463\n",
            "Validation score: 0.860008\n",
            "Iteration 52, loss = 0.00718091\n",
            "Validation score: 0.859779\n",
            "Iteration 53, loss = 0.00706123\n",
            "Validation score: 0.862764\n",
            "Iteration 54, loss = 0.00692905\n",
            "Validation score: 0.857553\n",
            "Iteration 55, loss = 0.00679986\n",
            "Validation score: 0.859438\n",
            "Iteration 56, loss = 0.00666992\n",
            "Validation score: 0.868111\n",
            "Iteration 57, loss = 0.00655435\n",
            "Validation score: 0.858886\n",
            "Iteration 58, loss = 0.00643481\n",
            "Validation score: 0.869280\n",
            "Iteration 59, loss = 0.00631945\n",
            "Validation score: 0.860000\n",
            "Iteration 60, loss = 0.00622334\n",
            "Validation score: 0.873809\n",
            "Iteration 61, loss = 0.00614055\n",
            "Validation score: 0.870783\n",
            "Iteration 62, loss = 0.00605191\n",
            "Validation score: 0.871365\n",
            "Iteration 63, loss = 0.00591233\n",
            "Validation score: 0.870469\n",
            "Iteration 64, loss = 0.00582128\n",
            "Validation score: 0.875468\n",
            "Iteration 65, loss = 0.00570705\n",
            "Validation score: 0.879498\n",
            "Iteration 66, loss = 0.00560983\n",
            "Validation score: 0.873144\n",
            "Iteration 67, loss = 0.00554215\n",
            "Validation score: 0.872336\n",
            "Iteration 68, loss = 0.00544973\n",
            "Validation score: 0.881107\n",
            "Iteration 69, loss = 0.00536351\n",
            "Validation score: 0.860602\n",
            "Iteration 70, loss = 0.00533649\n",
            "Validation score: 0.866366\n",
            "Iteration 71, loss = 0.00523844\n",
            "Validation score: 0.881651\n",
            "Iteration 72, loss = 0.00512575\n",
            "Validation score: 0.879911\n",
            "Iteration 73, loss = 0.00506435\n",
            "Validation score: 0.879244\n",
            "Iteration 74, loss = 0.00498210\n",
            "Validation score: 0.887600\n",
            "Iteration 75, loss = 0.00489788\n",
            "Validation score: 0.887427\n",
            "Iteration 76, loss = 0.00483212\n",
            "Validation score: 0.873204\n",
            "Iteration 77, loss = 0.00478275\n",
            "Validation score: 0.879869\n",
            "Iteration 78, loss = 0.00470707\n",
            "Validation score: 0.880908\n",
            "Iteration 79, loss = 0.00464192\n",
            "Validation score: 0.865702\n",
            "Iteration 80, loss = 0.00461081\n",
            "Validation score: 0.874350\n",
            "Iteration 81, loss = 0.00452487\n",
            "Validation score: 0.884484\n",
            "Iteration 82, loss = 0.00449143\n",
            "Validation score: 0.872825\n",
            "Iteration 83, loss = 0.00441908\n",
            "Validation score: 0.891968\n",
            "Iteration 84, loss = 0.00436661\n",
            "Validation score: 0.890647\n",
            "Iteration 85, loss = 0.00429650\n",
            "Validation score: 0.892988\n",
            "Iteration 86, loss = 0.00425235\n",
            "Validation score: 0.893090\n",
            "Iteration 87, loss = 0.00424604\n",
            "Validation score: 0.859455\n",
            "Iteration 88, loss = 0.00419045\n",
            "Validation score: 0.891994\n",
            "Iteration 89, loss = 0.00411401\n",
            "Validation score: 0.896260\n",
            "Iteration 90, loss = 0.00403923\n",
            "Validation score: 0.891768\n",
            "Iteration 91, loss = 0.00399860\n",
            "Validation score: 0.889617\n",
            "Iteration 92, loss = 0.00396538\n",
            "Validation score: 0.887053\n",
            "Iteration 93, loss = 0.00391568\n",
            "Validation score: 0.893963\n",
            "Iteration 94, loss = 0.00386331\n",
            "Validation score: 0.894018\n",
            "Iteration 95, loss = 0.00381867\n",
            "Validation score: 0.899010\n",
            "Iteration 96, loss = 0.00375897\n",
            "Validation score: 0.899037\n",
            "Iteration 97, loss = 0.00372739\n",
            "Validation score: 0.894371\n",
            "Iteration 98, loss = 0.00369675\n",
            "Validation score: 0.900275\n",
            "Iteration 99, loss = 0.00367528\n",
            "Validation score: 0.896903\n",
            "Iteration 100, loss = 0.00361751\n",
            "Validation score: 0.899421\n",
            "Iteration 101, loss = 0.00358223\n",
            "Validation score: 0.890861\n",
            "Iteration 102, loss = 0.00355075\n",
            "Validation score: 0.898261\n",
            "Iteration 103, loss = 0.00351630\n",
            "Validation score: 0.900711\n",
            "Iteration 104, loss = 0.00346152\n",
            "Validation score: 0.894354\n",
            "Iteration 105, loss = 0.00344130\n",
            "Validation score: 0.902887\n",
            "Iteration 106, loss = 0.00339831\n",
            "Validation score: 0.894623\n",
            "Iteration 107, loss = 0.00338914\n",
            "Validation score: 0.899832\n",
            "Iteration 108, loss = 0.00333440\n",
            "Validation score: 0.898155\n",
            "Iteration 109, loss = 0.00330645\n",
            "Validation score: 0.904057\n",
            "Iteration 110, loss = 0.00327915\n",
            "Validation score: 0.901387\n",
            "Iteration 111, loss = 0.00326001\n",
            "Validation score: 0.877503\n",
            "Iteration 112, loss = 0.00324858\n",
            "Validation score: 0.890977\n",
            "Iteration 113, loss = 0.00320839\n",
            "Validation score: 0.891833\n",
            "Iteration 114, loss = 0.00316409\n",
            "Validation score: 0.905819\n",
            "Iteration 115, loss = 0.00312020\n",
            "Validation score: 0.898298\n",
            "Iteration 116, loss = 0.00310566\n",
            "Validation score: 0.908507\n",
            "Iteration 117, loss = 0.00308534\n",
            "Validation score: 0.897571\n",
            "Iteration 118, loss = 0.00309077\n",
            "Validation score: 0.901023\n",
            "Iteration 119, loss = 0.00307024\n",
            "Validation score: 0.896982\n",
            "Iteration 120, loss = 0.00303832\n",
            "Validation score: 0.906711\n",
            "Iteration 121, loss = 0.00297775\n",
            "Validation score: 0.906038\n",
            "Iteration 122, loss = 0.00295124\n",
            "Validation score: 0.907306\n",
            "Iteration 123, loss = 0.00292656\n",
            "Validation score: 0.908433\n",
            "Iteration 124, loss = 0.00289786\n",
            "Validation score: 0.910854\n",
            "Iteration 125, loss = 0.00287141\n",
            "Validation score: 0.911117\n",
            "Iteration 126, loss = 0.00285712\n",
            "Validation score: 0.899002\n",
            "Iteration 127, loss = 0.00286594\n",
            "Validation score: 0.891914\n",
            "Iteration 128, loss = 0.00283422\n",
            "Validation score: 0.908708\n",
            "Iteration 129, loss = 0.00279507\n",
            "Validation score: 0.908887\n",
            "Iteration 130, loss = 0.00278470\n",
            "Validation score: 0.907707\n",
            "Iteration 131, loss = 0.00274839\n",
            "Validation score: 0.910310\n",
            "Iteration 132, loss = 0.00272835\n",
            "Validation score: 0.910042\n",
            "Iteration 133, loss = 0.00271355\n",
            "Validation score: 0.909459\n",
            "Iteration 134, loss = 0.00272623\n",
            "Validation score: 0.911234\n",
            "Iteration 135, loss = 0.00268580\n",
            "Validation score: 0.908157\n",
            "Iteration 136, loss = 0.00271082\n",
            "Validation score: 0.901670\n",
            "Iteration 137, loss = 0.00267715\n",
            "Validation score: 0.907478\n",
            "Iteration 138, loss = 0.00263671\n",
            "Validation score: 0.904898\n",
            "Iteration 139, loss = 0.00262958\n",
            "Validation score: 0.908371\n",
            "Iteration 140, loss = 0.00259491\n",
            "Validation score: 0.913303\n",
            "Iteration 141, loss = 0.00258605\n",
            "Validation score: 0.911659\n",
            "Iteration 142, loss = 0.00256453\n",
            "Validation score: 0.912752\n",
            "Iteration 143, loss = 0.00255358\n",
            "Validation score: 0.906944\n",
            "Iteration 144, loss = 0.00255797\n",
            "Validation score: 0.912353\n",
            "Iteration 145, loss = 0.00253885\n",
            "Validation score: 0.912621\n",
            "Iteration 146, loss = 0.00251220\n",
            "Validation score: 0.906784\n",
            "Iteration 147, loss = 0.00249827\n",
            "Validation score: 0.912899\n",
            "Iteration 148, loss = 0.00247961\n",
            "Validation score: 0.907546\n",
            "Iteration 149, loss = 0.00246052\n",
            "Validation score: 0.915648\n",
            "Iteration 150, loss = 0.00244154\n",
            "Validation score: 0.909248\n",
            "Iteration 151, loss = 0.00245128\n",
            "Validation score: 0.899539\n",
            "Iteration 152, loss = 0.00243299\n",
            "Validation score: 0.916113\n",
            "Iteration 153, loss = 0.00240263\n",
            "Validation score: 0.905638\n",
            "Iteration 154, loss = 0.00242427\n",
            "Validation score: 0.915092\n",
            "Iteration 155, loss = 0.00237690\n",
            "Validation score: 0.915078\n",
            "Iteration 156, loss = 0.00237298\n",
            "Validation score: 0.912995\n",
            "Iteration 157, loss = 0.00237353\n",
            "Validation score: 0.914839\n",
            "Iteration 158, loss = 0.00238964\n",
            "Validation score: 0.898123\n",
            "Iteration 159, loss = 0.00235735\n",
            "Validation score: 0.913571\n",
            "Iteration 160, loss = 0.00232463\n",
            "Validation score: 0.913367\n",
            "Iteration 161, loss = 0.00232677\n",
            "Validation score: 0.914099\n",
            "Iteration 162, loss = 0.00229889\n",
            "Validation score: 0.914083\n",
            "Iteration 163, loss = 0.00229838\n",
            "Validation score: 0.914264\n",
            "Validation score did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
            "Training score: 0.9376851728693755\n",
            "Validation score 0.9161126519601168\n",
            "Testing score: 0.9065349459532123\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import pickle\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# if mode is 'develop', it means that we will use the available data for training our model\n",
        "#if mode is 'evaluate', it means that we will load the model that was trained before (as well as any operators for data pre-processing) to make prediction on novel data\n",
        "mode = 'develop'\n",
        "\n",
        "#How many outputs (i.e., columns) your model should predict\n",
        "num_outputs  = 2\n",
        "\n",
        "if mode == 'develop':\n",
        "  #read data from file\n",
        "\n",
        "\n",
        "  #labeling columns name\n",
        "  labeling_data(robo)\n",
        "\n",
        "  #split data into inputs and outputs\n",
        "  X = robo.drop(['X_speed', 'Y_speed'], axis = 1) # inputs\n",
        "  y = robo[['X_speed', 'Y_speed']] # outputs\n",
        "\n",
        "  #feature engineering\n",
        "  X_feature_engineered = feature_engineering(X)\n",
        "\n",
        "\n",
        "\n",
        "  # split into train & test sets\n",
        "  x_train, x_test, y_train, y_test = train_test_split(X_feature_engineered, y, test_size=0.2, random_state=33)\n",
        "\n",
        "  # Standardise the traing data (similar to what we did in Lecture 4 - pages 15-16)\n",
        "  scaler = StandardScaler()\n",
        "  x_train_scaled = scaler.fit_transform(x_train)\n",
        "\n",
        "\n",
        "\n",
        "  #Train the model\n",
        "  # we specify that 10% of the training data will be used for validation. Ealy stopping is applied (similar to what we did in Lecture 4, page 33)\n",
        "  # we also use alpha =0.1 to activate L2 regularisation\n",
        "  model = MLPRegressor(hidden_layer_sizes=(150,150,150,150,150),learning_rate_init=0.001, batch_size= 1000, activation= 'relu', early_stopping = True, validation_fraction =0.2,alpha =0.1 , verbose = True)\n",
        "  model.fit(x_train_scaled, y_train)\n",
        "  train_score = model.score(x_train_scaled, y_train)\n",
        "  print(\"Training score:\", train_score)\n",
        "  print(\"Validation score\", model.best_validation_score_)\n",
        "\n",
        "  # test model\n",
        "  x_test_scaled = scaler.transform(x_test)\n",
        "\n",
        "  test_score = model.score(x_test_scaled, y_test)\n",
        "  print(\"Testing score:\", test_score)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "G6nEC-mRE3Wh"
      },
      "outputs": [],
      "source": [
        "# now save the model, the PCA object, the scaler object & the encoders so that you can load them at a later point & use them for novel data\n",
        "with open('Final.pkl', 'wb') as f:\n",
        "  pickle.dump(model, f)\n",
        "\n",
        "\n",
        "\n",
        "with open('scaler.pkl', 'wb') as f:\n",
        "  pickle.dump(scaler, f)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "vy49Uwnr00uv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model\n",
        "elif mode == 'evaluate':\n",
        "  # read the pre-trained model, the PCA object & the scaler object & encoders\n",
        "  model = pickle.load(open('Final.pkl', 'rb'))\n",
        "  scaler = pickle.load(open('scaler.pkl', 'rb'))\n",
        "\n",
        "\n",
        "  # Read novel data. This data usually has no output y. You'll need to use your model to predict y\n",
        "  novel_data= pd.read_csv('adult2.csv')\n",
        "\n",
        "  labeling_data(novel_data)\n",
        "\n",
        "  #split data into inputs and outputs\n",
        "  X = novel_data.drop(['X_speed', 'Y_speed'], axis = 1) # inputs\n",
        "  y = novel_data[['X_speed', 'Y_speed']] # outputs\n",
        "\n",
        "  #feature engineering\n",
        "  X_feature_engineered = feature_engineering(X)\n",
        "\n",
        "\n",
        "  X_scaler = scaler.transform(X_feature_engineered)\n",
        "  # standardise\n",
        "\n",
        "\n",
        "  model_score = model.score(X_scaler, y)\n",
        "  print(\"Model_score: \", model_score)\n",
        "\n"
      ],
      "metadata": {
        "id": "mmV9Glyw05X-"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}